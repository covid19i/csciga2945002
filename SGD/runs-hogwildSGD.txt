
On cuda3.cims.nyu.edu





[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000011763
Iteration no: 0, weight[432] = 0.0000011763
Training (log)loss: 2.3013022522	 thread:0
6162 correct out of 60000.	 Testing accuracy: 0.102700	 thread:0
1020 correct out of 10000.	 Testing accuracy: 0.102000	 thread:0
Iteration no: 1, weight[432] = 0.0000011763
Iteration no: 10, weight[432] = 0.0000302235
Training (log)loss: 2.2834004184	 thread:0
6329 correct out of 60000.	 Testing accuracy: 0.105483	 thread:0
1057 correct out of 10000.	 Testing accuracy: 0.105700	 thread:0
Iteration no: 100, weight[432] = 0.0002819181
Training (log)loss: 2.1403578769	 thread:0
7720 correct out of 60000.	 Testing accuracy: 0.128667	 thread:0
1257 correct out of 10000.	 Testing accuracy: 0.125700	 thread:0
Iteration no: 1000, weight[432] = 0.0021117650
Training (log)loss: 0.7902992187	 thread:0
13243 correct out of 60000.	 Testing accuracy: 0.220717	 thread:0
2181 correct out of 10000.	 Testing accuracy: 0.218100	 thread:0
Iteration no: 10000, weight[432] = 0.0174563217
Training (log)loss: -12.2221893045	 thread:0
14590 correct out of 60000.	 Testing accuracy: 0.243167	 thread:0
2397 correct out of 10000.	 Testing accuracy: 0.239700	 thread:0
Iteration no: 40000, weight[432] = 0.0495832575
Training (log)loss: -50.6986948851	 thread:0
19451 correct out of 60000.	 Testing accuracy: 0.324183	 thread:0
3202 correct out of 10000.	 Testing accuracy: 0.320200	 thread:0
Iteration no: 80000, weight[432] = 0.0968453422
Training (log)loss: -93.4492138277	 thread:0
20369 correct out of 60000.	 Testing accuracy: 0.339483	 thread:0
3326 correct out of 10000.	 Testing accuracy: 0.332600	 thread:0
Iteration no: 100000, weight[432] = 0.1134102896
Training (log)loss: -111.7266683436	 thread:0
20703 correct out of 60000.	 Testing accuracy: 0.345050	 thread:0
3396 correct out of 10000.	 Testing accuracy: 0.339600	 thread:0
Iteration no: 120000, weight[432] = 0.1272786420
Training (log)loss: -127.3862997785	 thread:0
20658 correct out of 60000.	 Testing accuracy: 0.344300	 thread:0
3367 correct out of 10000.	 Testing accuracy: 0.336700	 thread:0
Iteration no: 160000, weight[432] = 0.1513763494
Training (log)loss: -155.1687745391	 thread:0
20839 correct out of 60000.	 Testing accuracy: 0.347317	 thread:0
3400 correct out of 10000.	 Testing accuracy: 0.340000	 thread:0
Iteration no: 199999, weight[432] = 0.1843715201
Training (log)loss: -177.5223373869	 thread:0
21072 correct out of 60000.	 Testing accuracy: 0.351200	 thread:0
3454 correct out of 10000.	 Testing accuracy: 0.345400	 thread:0

Time elapsed in training = 123.282203 sec
Time elapsed in training per iteration = 0.000616 sec
new loss: -177.522337 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 2
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3454 correct out of 10000.	 Testing accuracy: 0.345400	 thread:0
End







[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000011765
Iteration no: 0, weight[432] = 0.0000011765
Training (log)loss: 2.3019360710	 thread:0
6340 correct out of 60000.	 Testing accuracy: 0.105667	 thread:0
1048 correct out of 10000.	 Testing accuracy: 0.104800	 thread:0
Iteration no: 1, weight[432] = 0.0000023529
Iteration no: 10, weight[432] = 0.0000607652
Training (log)loss: 2.2972356859	 thread:0
6292 correct out of 60000.	 Testing accuracy: 0.104867	 thread:0
1023 correct out of 10000.	 Testing accuracy: 0.102300	 thread:0
Iteration no: 100, weight[432] = 0.0001481743
Training (log)loss: 2.2276097728	 thread:0
7170 correct out of 60000.	 Testing accuracy: 0.119500	 thread:0
1170 correct out of 10000.	 Testing accuracy: 0.117000	 thread:0
Iteration no: 1000, weight[432] = 0.0019176615
Training (log)loss: 1.5057260676	 thread:0
7166 correct out of 60000.	 Testing accuracy: 0.119433	 thread:0
1232 correct out of 10000.	 Testing accuracy: 0.123200	 thread:0
Iteration no: 10000, weight[432] = 0.0096973723
Training (log)loss: -5.2693502313	 thread:0
12951 correct out of 60000.	 Testing accuracy: 0.215850	 thread:0
2180 correct out of 10000.	 Testing accuracy: 0.218000	 thread:0
Iteration no: 40000, weight[432] = 0.0332243599
Training (log)loss: -26.2745915840	 thread:0
17918 correct out of 60000.	 Testing accuracy: 0.298633	 thread:0
2992 correct out of 10000.	 Testing accuracy: 0.299200	 thread:0
Iteration no: 80000, weight[432] = 0.0694876832
Training (log)loss: -52.6727005281	 thread:0
19685 correct out of 60000.	 Testing accuracy: 0.328083	 thread:0
3236 correct out of 10000.	 Testing accuracy: 0.323600	 thread:0
Iteration no: 100000, weight[432] = 0.0945269016
Training (log)loss: -64.9349596892	 thread:0
20006 correct out of 60000.	 Testing accuracy: 0.333433	 thread:0
3300 correct out of 10000.	 Testing accuracy: 0.330000	 thread:0
Iteration no: 120000, weight[432] = 0.1009865274
Training (log)loss: -76.0696802605	 thread:0
19937 correct out of 60000.	 Testing accuracy: 0.332283	 thread:0
3264 correct out of 10000.	 Testing accuracy: 0.326400	 thread:0
Iteration no: 160000, weight[432] = 0.1296831486
Training (log)loss: -97.1993142448	 thread:0
20513 correct out of 60000.	 Testing accuracy: 0.341883	 thread:0
3321 correct out of 10000.	 Testing accuracy: 0.332100	 thread:0
Iteration no: 199999, weight[432] = 0.1490418673
Training (log)loss: -115.4823283954	 thread:0
20730 correct out of 60000.	 Testing accuracy: 0.345500	 thread:0
3362 correct out of 10000.	 Testing accuracy: 0.336200	 thread:0

Time elapsed in training = 118.767677 sec
Time elapsed in training per iteration = 0.000594 sec
new loss: -115.482328 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 1
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3362 correct out of 10000.	 Testing accuracy: 0.336200	 thread:0
End




[ir967@cuda3 SGD]$ ./hogwildSGD 
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
1000000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000011765
Iteration no: 0, weight[432] = 0.0000011765
Training (log)loss: 2.3019360710	 thread:0
6340 correct out of 60000.	 Testing accuracy: 0.105667	 thread:0
1048 correct out of 10000.	 Testing accuracy: 0.104800	 thread:0
Iteration no: 1, weight[432] = 0.0000023529
Iteration no: 10, weight[432] = 0.0000607652
Training (log)loss: 2.2972356859	 thread:0
6292 correct out of 60000.	 Testing accuracy: 0.104867	 thread:0
1023 correct out of 10000.	 Testing accuracy: 0.102300	 thread:0
Iteration no: 100, weight[432] = 0.0001481743
Training (log)loss: 2.2276097728	 thread:0
7170 correct out of 60000.	 Testing accuracy: 0.119500	 thread:0
1170 correct out of 10000.	 Testing accuracy: 0.117000	 thread:0
Iteration no: 1000, weight[432] = 0.0019176615
Training (log)loss: 1.5057260676	 thread:0
7166 correct out of 60000.	 Testing accuracy: 0.119433	 thread:0
1232 correct out of 10000.	 Testing accuracy: 0.123200	 thread:0
Iteration no: 10000, weight[432] = 0.0096973723
Training (log)loss: -5.2693502313	 thread:0
12951 correct out of 60000.	 Testing accuracy: 0.215850	 thread:0
2180 correct out of 10000.	 Testing accuracy: 0.218000	 thread:0
Iteration no: 100000, weight[432] = 0.0945269016
Training (log)loss: -64.9349596892	 thread:0
20006 correct out of 60000.	 Testing accuracy: 0.333433	 thread:0
3300 correct out of 10000.	 Testing accuracy: 0.330000	 thread:0
Iteration no: 200000, weight[432] = 0.1490432103
Training (log)loss: -115.4814183372	 thread:0
20730 correct out of 60000.	 Testing accuracy: 0.345500	 thread:0
3364 correct out of 10000.	 Testing accuracy: 0.336400	 thread:0
Iteration no: 400000, weight[432] = 0.2362742398
Training (log)loss: -183.0276989556	 thread:0
21133 correct out of 60000.	 Testing accuracy: 0.352217	 thread:0
3453 correct out of 10000.	 Testing accuracy: 0.345300	 thread:0
Iteration no: 600000, weight[432] = 0.3012493066
Training (log)loss: -222.9435874182	 thread:0
21368 correct out of 60000.	 Testing accuracy: 0.356133	 thread:0
3473 correct out of 10000.	 Testing accuracy: 0.347300	 thread:0
Iteration no: 800000, weight[432] = 0.3416902986
Training (log)loss: -248.6937980815	 thread:0
21455 correct out of 60000.	 Testing accuracy: 0.357583	 thread:0
3479 correct out of 10000.	 Testing accuracy: 0.347900	 thread:0
Iteration no: 999999, weight[432] = 0.3542084094
Training (log)loss: -265.4477568488	 thread:0
21591 correct out of 60000.	 Testing accuracy: 0.359850	 thread:0
3499 correct out of 10000.	 Testing accuracy: 0.349900	 thread:0

Time elapsed in training = 401.639975 sec
Time elapsed in training per iteration = 0.000402 sec
new loss: -265.447757 

No of iterations for each thread block: 1000000
No of threads in each block: 1024
No of blocks: 1
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3499 correct out of 10000.	 Testing accuracy: 0.349900	 thread:0
End





[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
1000000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000011763
Iteration no: 0, weight[432] = 0.0000011763
Training (log)loss: 2.3013077460	 thread:0
6095 correct out of 60000.	 Testing accuracy: 0.101583	 thread:0
1004 correct out of 10000.	 Testing accuracy: 0.100400	 thread:0
Iteration no: 1, weight[432] = 0.0000023528
Iteration no: 10, weight[432] = -0.0000176295
Training (log)loss: 2.2842235687	 thread:0
6328 correct out of 60000.	 Testing accuracy: 0.105467	 thread:0
1057 correct out of 10000.	 Testing accuracy: 0.105700	 thread:0
Iteration no: 100, weight[432] = 0.0002147336
Training (log)loss: 2.1455066262	 thread:0
7722 correct out of 60000.	 Testing accuracy: 0.128700	 thread:0
1257 correct out of 10000.	 Testing accuracy: 0.125700	 thread:0
Iteration no: 1000, weight[432] = 0.0018971538
Training (log)loss: 0.8231394541	 thread:0
13144 correct out of 60000.	 Testing accuracy: 0.219067	 thread:0
2161 correct out of 10000.	 Testing accuracy: 0.216100	 thread:0
Iteration no: 10000, weight[432] = 0.0151816818
Training (log)loss: -12.1587670142	 thread:0
14472 correct out of 60000.	 Testing accuracy: 0.241200	 thread:0
2366 correct out of 10000.	 Testing accuracy: 0.236600	 thread:0
Iteration no: 100000, weight[432] = 0.1101202493
Training (log)loss: -111.4484022395	 thread:0
20740 correct out of 60000.	 Testing accuracy: 0.345667	 thread:0
3397 correct out of 10000.	 Testing accuracy: 0.339700	 thread:0
Iteration no: 200000, weight[432] = 0.1715960807
Training (log)loss: -176.9890567740	 thread:0
21074 correct out of 60000.	 Testing accuracy: 0.351233	 thread:0
3453 correct out of 10000.	 Testing accuracy: 0.345300	 thread:0
Iteration no: 400000, weight[432] = 0.2521534643
Training (log)loss: -242.5238696003	 thread:0
21447 correct out of 60000.	 Testing accuracy: 0.357450	 thread:0
3497 correct out of 10000.	 Testing accuracy: 0.349700	 thread:0
Iteration no: 600000, weight[432] = 0.3238774134
Training (log)loss: -271.4628674586	 thread:0
21628 correct out of 60000.	 Testing accuracy: 0.360467	 thread:0
3514 correct out of 10000.	 Testing accuracy: 0.351400	 thread:0
Iteration no: 800000, weight[432] = 0.3510542329
Training (log)loss: -285.7406622033	 thread:0
21753 correct out of 60000.	 Testing accuracy: 0.362550	 thread:0
3502 correct out of 10000.	 Testing accuracy: 0.350200	 thread:0
Iteration no: 999999, weight[432] = 0.3778385589
Training (log)loss: -294.2883555176	 thread:0
21852 correct out of 60000.	 Testing accuracy: 0.364200	 thread:0
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0

Time elapsed in training = 432.265863 sec
Time elapsed in training per iteration = 0.000432 sec
new loss: -294.288356 

No of iterations for each thread block: 1000000
No of threads in each block: 1024
No of blocks: 2
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0
End







[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000302809
Iteration no: 0, weight[432] = 0.0000302809
Training (log)loss: 2.2868500593	 thread:0
6039 correct out of 60000.	 Testing accuracy: 0.100650	 thread:0
997 correct out of 10000.	 Testing accuracy: 0.099700	 thread:0
Iteration no: 1, weight[432] = 0.0001992098
Iteration no: 10, weight[432] = 0.0006407989
Training (log)loss: 2.0289769302	 thread:0
6179 correct out of 60000.	 Testing accuracy: 0.102983	 thread:0
1034 correct out of 10000.	 Testing accuracy: 0.103400	 thread:0
Iteration no: 100, weight[432] = 0.0040804262
Training (log)loss: 0.0835112855	 thread:0
8140 correct out of 60000.	 Testing accuracy: 0.135667	 thread:0
1350 correct out of 10000.	 Testing accuracy: 0.135000	 thread:0
Iteration no: 1000, weight[432] = 0.0306422826
Training (log)loss: -19.0269516832	 thread:0
16947 correct out of 60000.	 Testing accuracy: 0.282450	 thread:0
2749 correct out of 10000.	 Testing accuracy: 0.274900	 thread:0
Iteration no: 10000, weight[432] = 0.1829627497
Training (log)loss: -150.7112445645	 thread:0
20911 correct out of 60000.	 Testing accuracy: 0.348517	 thread:0
3371 correct out of 10000.	 Testing accuracy: 0.337100	 thread:0
Iteration no: 40000, weight[432] = 0.3645076325
Training (log)loss: -277.2030292821	 thread:0
21591 correct out of 60000.	 Testing accuracy: 0.359850	 thread:0
3505 correct out of 10000.	 Testing accuracy: 0.350500	 thread:0
Iteration no: 80000, weight[432] = 0.3829547782
Training (log)loss: -307.3924325868	 thread:0
21839 correct out of 60000.	 Testing accuracy: 0.363983	 thread:0
3530 correct out of 10000.	 Testing accuracy: 0.353000	 thread:0
Iteration no: 100000, weight[432] = 0.3849559875
Training (log)loss: -312.6082780013	 thread:0
21907 correct out of 60000.	 Testing accuracy: 0.365117	 thread:0
3511 correct out of 10000.	 Testing accuracy: 0.351100	 thread:0
Iteration no: 120000, weight[432] = 0.4073957106
Training (log)loss: -314.8519343314	 thread:0
22004 correct out of 60000.	 Testing accuracy: 0.366733	 thread:0
3545 correct out of 10000.	 Testing accuracy: 0.354500	 thread:0
Iteration no: 160000, weight[432] = 0.4115968071
Training (log)loss: -320.2041619058	 thread:0
22102 correct out of 60000.	 Testing accuracy: 0.368367	 thread:0
3517 correct out of 10000.	 Testing accuracy: 0.351700	 thread:0
Iteration no: 199999, weight[432] = 0.4231175923
Training (log)loss: -321.2983987389	 thread:0
22195 correct out of 60000.	 Testing accuracy: 0.369917	 thread:0
3539 correct out of 10000.	 Testing accuracy: 0.353900	 thread:0

Time elapsed in training = 451.138942 sec
Time elapsed in training per iteration = 0.002256 sec
new loss: -321.298399 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 64
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3539 correct out of 10000.	 Testing accuracy: 0.353900	 thread:0
End





[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000035270
Iteration no: 0, weight[432] = 0.0000035270
Training (log)loss: 2.2993473932	 thread:0
6081 correct out of 60000.	 Testing accuracy: 0.101350	 thread:0
1003 correct out of 10000.	 Testing accuracy: 0.100300	 thread:0
Iteration no: 1, weight[432] = 0.0000121517
Iteration no: 10, weight[432] = 0.0000555752
Training (log)loss: 2.2471109997	 thread:0
6130 correct out of 60000.	 Testing accuracy: 0.102167	 thread:0
1011 correct out of 10000.	 Testing accuracy: 0.101100	 thread:0
Iteration no: 100, weight[432] = 0.0008369895
Training (log)loss: 1.8810366633	 thread:0
10940 correct out of 60000.	 Testing accuracy: 0.182333	 thread:0
1819 correct out of 10000.	 Testing accuracy: 0.181900	 thread:0
Iteration no: 1000, weight[432] = 0.0060870564
Training (log)loss: -1.6064222409	 thread:0
12589 correct out of 60000.	 Testing accuracy: 0.209817	 thread:0
2082 correct out of 10000.	 Testing accuracy: 0.208200	 thread:0
Iteration no: 10000, weight[432] = 0.0297752333
Training (log)loss: -33.0533802550	 thread:0
17961 correct out of 60000.	 Testing accuracy: 0.299350	 thread:0
2892 correct out of 10000.	 Testing accuracy: 0.289200	 thread:0
Iteration no: 40000, weight[432] = 0.1046596941
Training (log)loss: -112.2973218688	 thread:0
20637 correct out of 60000.	 Testing accuracy: 0.343950	 thread:0
3383 correct out of 10000.	 Testing accuracy: 0.338300	 thread:0
Iteration no: 80000, weight[432] = 0.1850944910
Training (log)loss: -177.9815127181	 thread:0
21077 correct out of 60000.	 Testing accuracy: 0.351283	 thread:0
3450 correct out of 10000.	 Testing accuracy: 0.345000	 thread:0
Iteration no: 100000, weight[432] = 0.2231914390
Training (log)loss: -200.6973340834	 thread:0
21175 correct out of 60000.	 Testing accuracy: 0.352917	 thread:0
3488 correct out of 10000.	 Testing accuracy: 0.348800	 thread:0
Iteration no: 120000, weight[432] = 0.2399418302
Training (log)loss: -218.0210464391	 thread:0
21298 correct out of 60000.	 Testing accuracy: 0.354967	 thread:0
3476 correct out of 10000.	 Testing accuracy: 0.347600	 thread:0
Iteration no: 160000, weight[432] = 0.2805606499
Training (log)loss: -243.1849531171	 thread:0
21420 correct out of 60000.	 Testing accuracy: 0.357000	 thread:0
3493 correct out of 10000.	 Testing accuracy: 0.349300	 thread:0
Iteration no: 199999, weight[432] = 0.2965593501
Training (log)loss: -259.4997353815	 thread:0
21588 correct out of 60000.	 Testing accuracy: 0.359800	 thread:0
3490 correct out of 10000.	 Testing accuracy: 0.349000	 thread:0

Time elapsed in training = 141.911966 sec
Time elapsed in training per iteration = 0.000710 sec
new loss: -259.499735 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 8
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3490 correct out of 10000.	 Testing accuracy: 0.349000	 thread:0
End




[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000011765
Iteration no: 0, weight[432] = 0.0000011765
Training (log)loss: 2.3019360710	 thread:0
6340 correct out of 60000.	 Testing accuracy: 0.105667	 thread:0
1048 correct out of 10000.	 Testing accuracy: 0.104800	 thread:0
Iteration no: 1, weight[432] = 0.0000023529
Iteration no: 10, weight[432] = 0.0000607652
Training (log)loss: 2.2972356859	 thread:0
6292 correct out of 60000.	 Testing accuracy: 0.104867	 thread:0
1023 correct out of 10000.	 Testing accuracy: 0.102300	 thread:0
Iteration no: 100, weight[432] = 0.0001481743
Training (log)loss: 2.2276097728	 thread:0
7170 correct out of 60000.	 Testing accuracy: 0.119500	 thread:0
1170 correct out of 10000.	 Testing accuracy: 0.117000	 thread:0
Iteration no: 1000, weight[432] = 0.0019176615
Training (log)loss: 1.5057260676	 thread:0
7166 correct out of 60000.	 Testing accuracy: 0.119433	 thread:0
1232 correct out of 10000.	 Testing accuracy: 0.123200	 thread:0
Iteration no: 10000, weight[432] = 0.0096973723
Training (log)loss: -5.2693502313	 thread:0
12951 correct out of 60000.	 Testing accuracy: 0.215850	 thread:0
2180 correct out of 10000.	 Testing accuracy: 0.218000	 thread:0
Iteration no: 40000, weight[432] = 0.0332243599
Training (log)loss: -26.2745915840	 thread:0
17918 correct out of 60000.	 Testing accuracy: 0.298633	 thread:0
2992 correct out of 10000.	 Testing accuracy: 0.299200	 thread:0
Iteration no: 80000, weight[432] = 0.0694876832
Training (log)loss: -52.6727005281	 thread:0
19685 correct out of 60000.	 Testing accuracy: 0.328083	 thread:0
3236 correct out of 10000.	 Testing accuracy: 0.323600	 thread:0
Iteration no: 100000, weight[432] = 0.0945269016
Training (log)loss: -64.9349596892	 thread:0
20006 correct out of 60000.	 Testing accuracy: 0.333433	 thread:0
3300 correct out of 10000.	 Testing accuracy: 0.330000	 thread:0
Iteration no: 120000, weight[432] = 0.1009865274
Training (log)loss: -76.0696802605	 thread:0
19937 correct out of 60000.	 Testing accuracy: 0.332283	 thread:0
3264 correct out of 10000.	 Testing accuracy: 0.326400	 thread:0
Iteration no: 160000, weight[432] = 0.1296831486
Training (log)loss: -97.1993142448	 thread:0
20513 correct out of 60000.	 Testing accuracy: 0.341883	 thread:0
3321 correct out of 10000.	 Testing accuracy: 0.332100	 thread:0
Iteration no: 199999, weight[432] = 0.1490418673
Training (log)loss: -115.4823283954	 thread:0
20730 correct out of 60000.	 Testing accuracy: 0.345500	 thread:0
3362 correct out of 10000.	 Testing accuracy: 0.336200	 thread:0

Time elapsed in training = 118.767677 sec
Time elapsed in training per iteration = 0.000594 sec
new loss: -115.482328 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 1
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3362 correct out of 10000.	 Testing accuracy: 0.336200	 thread:0
End





[ir967@cuda3 SGD]$ nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr;
[ir967@cuda3 SGD]$ ./hogwildSGD 
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000035277
Iteration no: 0, weight[432] = 0.0000035277
Training (log)loss: 2.2999841847	 thread:0
6074 correct out of 60000.	 Testing accuracy: 0.101233	 thread:0
1003 correct out of 10000.	 Testing accuracy: 0.100300	 thread:0
Iteration no: 1, weight[432] = -0.0000058839
Iteration no: 10, weight[432] = 0.0001110763
Training (log)loss: 2.2710162735	 thread:0
6306 correct out of 60000.	 Testing accuracy: 0.105100	 thread:0
1032 correct out of 10000.	 Testing accuracy: 0.103200	 thread:0
Iteration no: 100, weight[432] = -0.0000232513
Training (log)loss: 2.0220523036	 thread:0
8959 correct out of 60000.	 Testing accuracy: 0.149317	 thread:0
1500 correct out of 10000.	 Testing accuracy: 0.150000	 thread:0
Iteration no: 1000, weight[432] = 0.0022272280
Training (log)loss: -0.6383038804	 thread:0
10028 correct out of 60000.	 Testing accuracy: 0.167133	 thread:0
1639 correct out of 10000.	 Testing accuracy: 0.163900	 thread:0
Iteration no: 10000, weight[432] = 0.0262605690
Training (log)loss: -25.7075794205	 thread:0
17012 correct out of 60000.	 Testing accuracy: 0.283533	 thread:0
2789 correct out of 10000.	 Testing accuracy: 0.278900	 thread:0
Iteration no: 40000, weight[432] = 0.1021437320
Training (log)loss: -92.1533412605	 thread:0
20514 correct out of 60000.	 Testing accuracy: 0.341900	 thread:0
3386 correct out of 10000.	 Testing accuracy: 0.338600	 thread:0
Iteration no: 80000, weight[432] = 0.1783410306
Training (log)loss: -153.3305884932	 thread:0
20964 correct out of 60000.	 Testing accuracy: 0.349400	 thread:0
3428 correct out of 10000.	 Testing accuracy: 0.342800	 thread:0
Iteration no: 100000, weight[432] = 0.2189706142
Training (log)loss: -175.7436600739	 thread:0
21092 correct out of 60000.	 Testing accuracy: 0.351533	 thread:0
3465 correct out of 10000.	 Testing accuracy: 0.346500	 thread:0
Iteration no: 120000, weight[432] = 0.2349627410
Training (log)loss: -193.5305493110	 thread:0
21130 correct out of 60000.	 Testing accuracy: 0.352167	 thread:0
3464 correct out of 10000.	 Testing accuracy: 0.346400	 thread:0
Iteration no: 160000, weight[432] = 0.2770885245
Training (log)loss: -221.8456211921	 thread:0
21304 correct out of 60000.	 Testing accuracy: 0.355067	 thread:0
3477 correct out of 10000.	 Testing accuracy: 0.347700	 thread:0
Iteration no: 199999, weight[432] = 0.3064007411
Training (log)loss: -241.0347167517	 thread:0
21437 correct out of 60000.	 Testing accuracy: 0.357283	 thread:0
3492 correct out of 10000.	 Testing accuracy: 0.349200	 thread:0

Time elapsed in training = 137.629988 sec
Time elapsed in training per iteration = 0.000688 sec
new loss: -241.034717 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 4
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3492 correct out of 10000.	 Testing accuracy: 0.349200	 thread:0
End




[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr;
[ir967@cuda3 SGD]$ ./hogwildSGD 
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000047007
Iteration no: 0, weight[432] = 0.0000047007
Training (log)loss: 2.2971466850	 thread:0
6063 correct out of 60000.	 Testing accuracy: 0.101050	 thread:0
1004 correct out of 10000.	 Testing accuracy: 0.100400	 thread:0
Iteration no: 1, weight[432] = -0.0000074550
Iteration no: 10, weight[432] = -0.0002740105
Training (log)loss: 2.2526234965	 thread:0
6131 correct out of 60000.	 Testing accuracy: 0.102183	 thread:0
1010 correct out of 10000.	 Testing accuracy: 0.101000	 thread:0
Iteration no: 100, weight[432] = 0.0006842812
Training (log)loss: 1.7801321601	 thread:0
7995 correct out of 60000.	 Testing accuracy: 0.133250	 thread:0
1361 correct out of 10000.	 Testing accuracy: 0.136100	 thread:0
Iteration no: 1000, weight[432] = 0.0077437642
Training (log)loss: -3.1549967059	 thread:0
12402 correct out of 60000.	 Testing accuracy: 0.206700	 thread:0
2081 correct out of 10000.	 Testing accuracy: 0.208100	 thread:0
Iteration no: 10000, weight[432] = 0.0432403981
Training (log)loss: -46.8572412410	 thread:0
19652 correct out of 60000.	 Testing accuracy: 0.327533	 thread:0
3182 correct out of 10000.	 Testing accuracy: 0.318200	 thread:0
Iteration no: 40000, weight[432] = 0.1434308835
Training (log)loss: -144.2470985172	 thread:0
20985 correct out of 60000.	 Testing accuracy: 0.349750	 thread:0
3455 correct out of 10000.	 Testing accuracy: 0.345500	 thread:0
Iteration no: 80000, weight[432] = 0.2376864984
Training (log)loss: -212.8647545851	 thread:0
21298 correct out of 60000.	 Testing accuracy: 0.354967	 thread:0
3460 correct out of 10000.	 Testing accuracy: 0.346000	 thread:0
Iteration no: 100000, weight[432] = 0.2869254695
Training (log)loss: -233.5574203212	 thread:0
21426 correct out of 60000.	 Testing accuracy: 0.357100	 thread:0
3475 correct out of 10000.	 Testing accuracy: 0.347500	 thread:0
Iteration no: 120000, weight[432] = 0.3140654749
Training (log)loss: -248.3900634056	 thread:0
21549 correct out of 60000.	 Testing accuracy: 0.359150	 thread:0
3485 correct out of 10000.	 Testing accuracy: 0.348500	 thread:0
Iteration no: 160000, weight[432] = 0.3450984327
Training (log)loss: -268.5832674896	 thread:0
21582 correct out of 60000.	 Testing accuracy: 0.359700	 thread:0
3518 correct out of 10000.	 Testing accuracy: 0.351800	 thread:0
Iteration no: 199999, weight[432] = 0.3548957638
Training (log)loss: -280.7865307654	 thread:0
21654 correct out of 60000.	 Testing accuracy: 0.360900	 thread:0
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0

Time elapsed in training = 155.535668 sec
Time elapsed in training per iteration = 0.000778 sec
new loss: -280.786531 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 16
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0
End




[ir967@cuda3 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000152430
Iteration no: 0, weight[432] = 0.0000152430
Training (log)loss: 2.2925784363	 thread:0
6046 correct out of 60000.	 Testing accuracy: 0.100767	 thread:0
999 correct out of 10000.	 Testing accuracy: 0.099900	 thread:0
Iteration no: 1, weight[432] = -0.0000177253
Iteration no: 10, weight[432] = -0.0000405696
Training (log)loss: 2.1804862954	 thread:0
6125 correct out of 60000.	 Testing accuracy: 0.102083	 thread:0
1007 correct out of 10000.	 Testing accuracy: 0.100700	 thread:0
Iteration no: 100, weight[432] = 0.0011291094
Training (log)loss: 1.1335428694	 thread:0
6144 correct out of 60000.	 Testing accuracy: 0.102400	 thread:0
1009 correct out of 10000.	 Testing accuracy: 0.100900	 thread:0
Iteration no: 1000, weight[432] = 0.0107315821
Training (log)loss: -8.7002737355	 thread:0
14075 correct out of 60000.	 Testing accuracy: 0.234583	 thread:0
2337 correct out of 10000.	 Testing accuracy: 0.233700	 thread:0
Iteration no: 10000, weight[432] = 0.0999891059
Training (log)loss: -90.1093225955	 thread:0
20521 correct out of 60000.	 Testing accuracy: 0.342017	 thread:0
3305 correct out of 10000.	 Testing accuracy: 0.330500	 thread:0
Iteration no: 40000, weight[432] = 0.2535570134
Training (log)loss: -220.3821688809	 thread:0
21381 correct out of 60000.	 Testing accuracy: 0.356350	 thread:0
3475 correct out of 10000.	 Testing accuracy: 0.347500	 thread:0
Iteration no: 80000, weight[432] = 0.3148354599
Training (log)loss: -275.1332304515	 thread:0
21592 correct out of 60000.	 Testing accuracy: 0.359867	 thread:0
3491 correct out of 10000.	 Testing accuracy: 0.349100	 thread:0
Iteration no: 100000, weight[432] = 0.3471458111
Training (log)loss: -287.4681895582	 thread:0
21703 correct out of 60000.	 Testing accuracy: 0.361717	 thread:0
3506 correct out of 10000.	 Testing accuracy: 0.350600	 thread:0
Iteration no: 120000, weight[432] = 0.3716508103
Training (log)loss: -295.4092666168	 thread:0
21800 correct out of 60000.	 Testing accuracy: 0.363333	 thread:0
3518 correct out of 10000.	 Testing accuracy: 0.351800	 thread:0
Iteration no: 160000, weight[432] = 0.3649979022
Training (log)loss: -304.6871000191	 thread:0
21901 correct out of 60000.	 Testing accuracy: 0.365017	 thread:0
3530 correct out of 10000.	 Testing accuracy: 0.353000	 thread:0
Iteration no: 199999, weight[432] = 0.3681586791
Training (log)loss: -308.2100457872	 thread:0
21953 correct out of 60000.	 Testing accuracy: 0.365883	 thread:0
3530 correct out of 10000.	 Testing accuracy: 0.353000	 thread:0

Time elapsed in training = 230.499940 sec
Time elapsed in training per iteration = 0.001152 sec
new loss: -308.210046 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 32
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3530 correct out of 10000.	 Testing accuracy: 0.353000	 thread:0
End






On cuda2.cims.nyu.edu


[ir967@cuda2 SGD]$ nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD; rm -f hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
Iteration no: 0, weight[432] = 0.0000082263
Iteration no: 0, weight[432] = 0.0000082263
Training (log)loss: 2.2992419436	 thread:0
6157 correct out of 60000.	 Testing accuracy: 0.102617	 thread:0
1025 correct out of 10000.	 Testing accuracy: 0.102500	 thread:0
Iteration no: 1, weight[432] = 0.0000094026
Iteration no: 10, weight[432] = 0.0000641190
Training (log)loss: 2.2266787264	 thread:0
6547 correct out of 60000.	 Testing accuracy: 0.109117	 thread:0
1075 correct out of 10000.	 Testing accuracy: 0.107500	 thread:0
Iteration no: 100, weight[432] = 0.0001573637
Training (log)loss: 1.7691780342	 thread:0
9926 correct out of 60000.	 Testing accuracy: 0.165433	 thread:0
1573 correct out of 10000.	 Testing accuracy: 0.157300	 thread:0
Iteration no: 1000, weight[432] = 0.0126483279
Training (log)loss: -2.7796292303	 thread:0
13570 correct out of 60000.	 Testing accuracy: 0.226167	 thread:0
2259 correct out of 10000.	 Testing accuracy: 0.225900	 thread:0
Iteration no: 10000, weight[432] = 0.0643458458
Training (log)loss: -43.9788302158	 thread:0
19221 correct out of 60000.	 Testing accuracy: 0.320350	 thread:0
3107 correct out of 10000.	 Testing accuracy: 0.310700	 thread:0
Iteration no: 40000, weight[432] = 0.1944620787
Training (log)loss: -139.4798429496	 thread:0
20891 correct out of 60000.	 Testing accuracy: 0.348183	 thread:0
3409 correct out of 10000.	 Testing accuracy: 0.340900	 thread:0
Iteration no: 80000, weight[432] = 0.2835152045
Training (log)loss: -207.9754847262	 thread:0
21205 correct out of 60000.	 Testing accuracy: 0.353417	 thread:0
3465 correct out of 10000.	 Testing accuracy: 0.346500	 thread:0
Iteration no: 100000, weight[432] = 0.3269492777
Training (log)loss: -229.6086932742	 thread:0
21326 correct out of 60000.	 Testing accuracy: 0.355433	 thread:0
3491 correct out of 10000.	 Testing accuracy: 0.349100	 thread:0
Iteration no: 120000, weight[432] = 0.3432735632
Training (log)loss: -244.8456832872	 thread:0
21425 correct out of 60000.	 Testing accuracy: 0.357083	 thread:0
3506 correct out of 10000.	 Testing accuracy: 0.350600	 thread:0
Iteration no: 160000, weight[432] = 0.3593171581
Training (log)loss: -266.1509113282	 thread:0
21610 correct out of 60000.	 Testing accuracy: 0.360167	 thread:0
3527 correct out of 10000.	 Testing accuracy: 0.352700	 thread:0
Iteration no: 199999, weight[432] = 0.3842831032
Training (log)loss: -279.7061422902	 thread:0
21685 correct out of 60000.	 Testing accuracy: 0.361417	 thread:0
3527 correct out of 10000.	 Testing accuracy: 0.352700	 thread:0

Time elapsed in training = 165.991442 sec
Time elapsed in training per iteration = 0.000830 sec
new loss: -279.706142 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 16
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3527 correct out of 10000.	 Testing accuracy: 0.352700	 thread:0
End







[ir967@cuda2 SGD]$ nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD; rm -f hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
200000
old loss: 2.302585 
weight[432] = 0.000000
first term for weight[432]= -0.0011764706	 for label 0	 block: 0
first term for weight[432]= -0.0011764706	 for label 0	 block: 1
first term for weight[432]= -0.0011764706	 for label 0	 block: 4
first term for weight[432]= -0.0011761440	 for label 0	 block: 5
first term for weight[432]= -0.0011761779	 for label 0	 block: 2
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 0
first term for weight[432]= -0.0011757162	 for label 0	 block: 6
first term for weight[432]= -0.0011757530	 for label 0	 block: 3
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 4
first term for weight[432]= -0.0011749510	 for label 0	 block: 7
second term for weight[432]= 0.00000000000003921569	 for label 0	 block: 5
second term for weight[432]= 0.00000000000003921569	 for label 0	 block: 2
second term for weight[432]= 0.00000000000003921569	 for label 0	 block: 6
second term for weight[432]= 0.00000000000003921569	 for label 0	 block: 3
second term for weight[432]= 0.00000000000011764706	 for label 0	 block: 7
Iteration no: 0, weight[432] = 0.0000082320
Iteration no: 0, weight[432] = 0.0000082320
Training (log)loss: 2.3003755838	 thread:0
5849 correct out of 60000.	 Testing accuracy: 0.097483	 thread:0
976 correct out of 10000.	 Testing accuracy: 0.097600	 thread:0
first term for weight[432]= -0.0011765867	 for label 0	 block: 0
first term for weight[432]= 0.0121568579	 for label 0	 block: 4
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
first term for weight[432]= 0.0105901538	 for label 0	 block: 2
first term for weight[432]= 0.0000000000	 for label 0	 block: 5
second term for weight[432]= 0.00000000000027439920	 for label 0	 block: 0
first term for weight[432]= -0.0000000000	 for label 0	 block: 6
first term for weight[432]= -0.0000000000	 for label 0	 block: 3
second term for weight[432]= 0.00000000000027439920	 for label 0	 block: 4
second term for weight[432]= 0.00000000000027439920	 for label 0	 block: 1
first term for weight[432]= -0.0074489710	 for label 0	 block: 7
second term for weight[432]= 0.00000000000031361876	 for label 0	 block: 5
second term for weight[432]= 0.00000000000031361876	 for label 0	 block: 2
second term for weight[432]= 0.00000000000031361876	 for label 0	 block: 6
second term for weight[432]= 0.00000000000031361876	 for label 0	 block: 3
second term for weight[432]= -0.00000000000009160984	 for label 0	 block: 7
Iteration no: 1, weight[432] = -0.0000058895
first term for weight[432]= -0.0094186657	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 4
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
first term for weight[432]= 0.0000000000	 for label 0	 block: 5
first term for weight[432]= -0.0000000000	 for label 0	 block: 2
second term for weight[432]= -0.00000000000019631593	 for label 0	 block: 0
second term for weight[432]= -0.00000000000019631593	 for label 0	 block: 4
second term for weight[432]= -0.00000000000019631593	 for label 0	 block: 1
first term for weight[432]= -0.0015701334	 for label 0	 block: 3
first term for weight[432]= -0.0011776335	 for label 0	 block: 6
first term for weight[432]= -0.0019605334	 for label 0	 block: 7
second term for weight[432]= -0.00000000000019631593	 for label 0	 block: 5
second term for weight[432]= 0.00000000000011763959	 for label 0	 block: 2
second term for weight[432]= 0.00000000000011763959	 for label 0	 block: 6
second term for weight[432]= 0.00000000000011763959	 for label 0	 block: 3
second term for weight[432]= 0.00000000000011763959	 for label 0	 block: 7
Iteration no: 2, weight[432] = 0.0000082375
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 4
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
first term for weight[432]= -0.0329449161	 for label 0	 block: 2
first term for weight[432]= 0.0309837254	 for label 0	 block: 5
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 0
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 4
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 1
first term for weight[432]= 0.0000000000	 for label 0	 block: 6
first term for weight[432]= 0.0000000000	 for label 0	 block: 3
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 5
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 2
first term for weight[432]= -0.0451035997	 for label 0	 block: 7
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 3
second term for weight[432]= 0.00000000000027458293	 for label 0	 block: 6
second term for weight[432]= -0.00000000000075820791	 for label 0	 block: 7
Iteration no: 3, weight[432] = 0.0000223574
first term for weight[432]= -0.0000000000	 for label 0	 block: 0
first term for weight[432]= -0.0000000000	 for label 0	 block: 4
first term for weight[432]= 0.0200083662	 for label 0	 block: 1
first term for weight[432]= -0.0317648012	 for label 0	 block: 5
first term for weight[432]= -0.0043103830	 for label 0	 block: 2
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 0
first term for weight[432]= -0.0003921829	 for label 0	 block: 6
first term for weight[432]= -0.0113763641	 for label 0	 block: 3
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 4
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 1
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 5
first term for weight[432]= -0.0011769798	 for label 0	 block: 7
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 2
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 6
second term for weight[432]= 0.00000000000074524541	 for label 0	 block: 3
second term for weight[432]= 0.00000000000128080601	 for label 0	 block: 7
Iteration no: 4, weight[432] = 0.0000513697
Iteration no: 10, weight[432] = 0.0001417045
Training (log)loss: 2.2473452321	 thread:0
6131 correct out of 60000.	 Testing accuracy: 0.102183	 thread:0
1011 correct out of 10000.	 Testing accuracy: 0.101100	 thread:0
Iteration no: 100, weight[432] = 0.0013517718
Training (log)loss: 1.9507583758	 thread:0
9899 correct out of 60000.	 Testing accuracy: 0.164983	 thread:0
1672 correct out of 10000.	 Testing accuracy: 0.167200	 thread:0
Iteration no: 1000, weight[432] = 0.0076382111
Training (log)loss: -1.2813811960	 thread:0
8193 correct out of 60000.	 Testing accuracy: 0.136550	 thread:0
1373 correct out of 10000.	 Testing accuracy: 0.137300	 thread:0
Iteration no: 10000, weight[432] = 0.0507961000
Training (log)loss: -31.1675526240	 thread:0
17929 correct out of 60000.	 Testing accuracy: 0.298817	 thread:0
2913 correct out of 10000.	 Testing accuracy: 0.291300	 thread:0
first term for weight[432]= -0.0010112884	 for label 0	 block: 0
first term for weight[432]= -0.0008905207	 for label 0	 block: 4
first term for weight[432]= -0.0349218050	 for label 0	 block: 1
second term for weight[432]= 0.00000000515102486362	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 2
first term for weight[432]= 0.0000000000	 for label 0	 block: 5
second term for weight[432]= 0.00000000515102486362	 for label 0	 block: 4
second term for weight[432]= 0.00000000515102486362	 for label 0	 block: 1
first term for weight[432]= -0.0005396722	 for label 0	 block: 3
first term for weight[432]= 0.0000000000	 for label 0	 block: 6
second term for weight[432]= 0.00000000515105857306	 for label 0	 block: 2
second term for weight[432]= 0.00000000515105857306	 for label 0	 block: 5
first term for weight[432]= 0.0000000000	 for label 0	 block: 7
second term for weight[432]= 0.00000000515225231691	 for label 0	 block: 3
second term for weight[432]= 0.00000000515225231691	 for label 0	 block: 6
second term for weight[432]= 0.00000000515225231656	 for label 0	 block: 7
Iteration no: 40000, weight[432] = 0.1545681092
Training (log)loss: -106.7473831041	 thread:0
20758 correct out of 60000.	 Testing accuracy: 0.345967	 thread:0
3377 correct out of 10000.	 Testing accuracy: 0.337700	 thread:0
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0068476851	 for label 0	 block: 4
first term for weight[432]= 0.0074820390	 for label 0	 block: 1
second term for weight[432]= 0.00000000864147020350	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 2
first term for weight[432]= 0.0000000000	 for label 0	 block: 5
second term for weight[432]= 0.00000000864147020350	 for label 0	 block: 4
second term for weight[432]= 0.00000000864147020350	 for label 0	 block: 1
first term for weight[432]= -0.0029268144	 for label 0	 block: 3
first term for weight[432]= 0.0416890512	 for label 0	 block: 6
second term for weight[432]= 0.00000000864147020321	 for label 0	 block: 2
second term for weight[432]= 0.00000000864147020321	 for label 0	 block: 5
first term for weight[432]= 0.0000000000	 for label 0	 block: 7
second term for weight[432]= 0.00000000864099254517	 for label 0	 block: 3
second term for weight[432]= 0.00000000864099254517	 for label 0	 block: 6
second term for weight[432]= 0.00000000864099254459	 for label 0	 block: 7
Iteration no: 80000, weight[432] = 0.2591880873
Training (log)loss: -171.4284621978	 thread:0
21080 correct out of 60000.	 Testing accuracy: 0.351333	 thread:0
3439 correct out of 10000.	 Testing accuracy: 0.343900	 thread:0
Iteration no: 100000, weight[432] = 0.2969460487
Training (log)loss: -194.5384646763	 thread:0
21153 correct out of 60000.	 Testing accuracy: 0.352550	 thread:0
3453 correct out of 10000.	 Testing accuracy: 0.345300	 thread:0
first term for weight[432]= -0.0082219393	 for label 0	 block: 0
first term for weight[432]= -0.0001606741	 for label 0	 block: 1
first term for weight[432]= -0.0003327503	 for label 0	 block: 4
second term for weight[432]= 0.00000001026513080566	 for label 0	 block: 0
first term for weight[432]= 0.0128734934	 for label 0	 block: 5
first term for weight[432]= 0.0019280608	 for label 0	 block: 2
second term for weight[432]= 0.00000001026513080566	 for label 0	 block: 1
second term for weight[432]= 0.00000001026513080566	 for label 0	 block: 4
first term for weight[432]= -0.0006873486	 for label 0	 block: 3
first term for weight[432]= 0.0000000000	 for label 0	 block: 6
second term for weight[432]= 0.00000001026540486996	 for label 0	 block: 5
second term for weight[432]= 0.00000001026540486996	 for label 0	 block: 2
first term for weight[432]= -0.0000000000	 for label 0	 block: 7
second term for weight[432]= 0.00000001026542131676	 for label 0	 block: 3
second term for weight[432]= 0.00000001026542131676	 for label 0	 block: 6
second term for weight[432]= 0.00000001026492793093	 for label 0	 block: 7
Iteration no: 120000, weight[432] = 0.3079485252
Training (log)loss: -211.8421246549	 thread:0
21241 correct out of 60000.	 Testing accuracy: 0.354017	 thread:0
3478 correct out of 10000.	 Testing accuracy: 0.347800	 thread:0
first term for weight[432]= -0.0011729138	 for label 0	 block: 0
first term for weight[432]= -0.0007526726	 for label 0	 block: 4
first term for weight[432]= -0.0004619724	 for label 0	 block: 1
second term for weight[432]= 0.00000001148906291695	 for label 0	 block: 0
first term for weight[432]= -0.0200924024	 for label 0	 block: 2
first term for weight[432]= -0.0112120005	 for label 0	 block: 5
second term for weight[432]= 0.00000001148906291695	 for label 0	 block: 4
second term for weight[432]= 0.00000001148906291695	 for label 0	 block: 1
first term for weight[432]= 0.0000000000	 for label 0	 block: 6
first term for weight[432]= 0.0146991368	 for label 0	 block: 3
second term for weight[432]= 0.00000001148910201369	 for label 0	 block: 5
second term for weight[432]= 0.00000001148910201369	 for label 0	 block: 2
first term for weight[432]= 0.0000000000	 for label 0	 block: 7
second term for weight[432]= 0.00000001148914250109	 for label 0	 block: 6
second term for weight[432]= 0.00000001148914250109	 for label 0	 block: 3
second term for weight[432]= 0.00000001149018598043	 for label 0	 block: 7
Iteration no: 160000, weight[432] = 0.3446908802
Training (log)loss: -237.7570998413	 thread:0
21392 correct out of 60000.	 Testing accuracy: 0.356533	 thread:0
3493 correct out of 10000.	 Testing accuracy: 0.349300	 thread:0
first term for weight[432]= 0.0414827458	 for label 0	 block: 0
first term for weight[432]= -0.0001149625	 for label 0	 block: 1
first term for weight[432]= 0.0033202029	 for label 0	 block: 4
first term for weight[432]= -0.0001515586	 for label 0	 block: 2
first term for weight[432]= -0.0004334442	 for label 0	 block: 5
second term for weight[432]= 0.00000001242185037386	 for label 0	 block: 0
second term for weight[432]= 0.00000001242185037386	 for label 0	 block: 1
second term for weight[432]= 0.00000001242185037386	 for label 0	 block: 4
first term for weight[432]= 0.0000000000	 for label 0	 block: 3
first term for weight[432]= 0.0000000000	 for label 0	 block: 6
second term for weight[432]= 0.00000001242185037386	 for label 0	 block: 2
second term for weight[432]= 0.00000001242185037386	 for label 0	 block: 5
first term for weight[432]= 0.0101490258	 for label 0	 block: 7
second term for weight[432]= 0.00000001242036077308	 for label 0	 block: 3
second term for weight[432]= 0.00000001242036077308	 for label 0	 block: 6
second term for weight[432]= 0.00000001242038027234	 for label 0	 block: 7
Iteration no: 199999, weight[432] = 0.3726012591
Training (log)loss: -256.1958248929	 thread:0
21495 correct out of 60000.	 Testing accuracy: 0.358250	 thread:0
3490 correct out of 10000.	 Testing accuracy: 0.349000	 thread:0

Time elapsed in training = 154.483718 sec
Time elapsed in training per iteration = 0.000772 sec
new loss: -256.195825 

No of iterations for each thread block: 200000
No of threads in each block: 1024
No of blocks: 8
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3490 correct out of 10000.	 Testing accuracy: 0.349000	 thread:0
End








[ir967@cuda2 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
1000000
old loss: 2.302585 
weight[432] = 0.000000
first term for weight[432]= -0.0011764706	 for label 0	 block: 0
first term for weight[432]= -0.0011764706	 for label 0	 block: 1
first term for weight[432]= -0.0011761329	 for label 0	 block: 2
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 0
first term for weight[432]= -0.0011757364	 for label 0	 block: 3
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 2
second term for weight[432]= 0.00000000000007843137	 for label 0	 block: 3
Iteration no: 0, weight[432] = 0.0000047048
Iteration no: 0, weight[432] = 0.0000047048
Training (log)loss: 2.3009229658	 thread:0
6028 correct out of 60000.	 Testing accuracy: 0.100467	 thread:0
1010 correct out of 10000.	 Testing accuracy: 0.101000	 thread:0
first term for weight[432]= -0.0011763616	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000015682702	 for label 0	 block: 0
first term for weight[432]= 0.0105881554	 for label 0	 block: 2
second term for weight[432]= 0.00000000000015682702	 for label 0	 block: 1
first term for weight[432]= -0.0000000000	 for label 0	 block: 3
second term for weight[432]= 0.00000000000019603907	 for label 0	 block: 2
second term for weight[432]= 0.00000000000019603907	 for label 0	 block: 3
Iteration no: 1, weight[432] = -0.0000047070
first term for weight[432]= -0.0094158386	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= -0.00000000000015689944	 for label 0	 block: 0
first term for weight[432]= -0.0000000000	 for label 0	 block: 2
second term for weight[432]= -0.00000000000015689944	 for label 0	 block: 1
first term for weight[432]= -0.0015697657	 for label 0	 block: 3
second term for weight[432]= 0.00000000000015696184	 for label 0	 block: 2
second term for weight[432]= 0.00000000000015696184	 for label 0	 block: 3
Iteration no: 2, weight[432] = 0.0000062786
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000020928737	 for label 0	 block: 0
first term for weight[432]= -0.0329700811	 for label 0	 block: 2
second term for weight[432]= 0.00000000000020928737	 for label 0	 block: 1
first term for weight[432]= 0.0000000000	 for label 0	 block: 3
second term for weight[432]= 0.00000000000020928737	 for label 0	 block: 2
second term for weight[432]= 0.00000000000020928737	 for label 0	 block: 3
Iteration no: 3, weight[432] = 0.0000392487
first term for weight[432]= -0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0200189507	 for label 0	 block: 1
second term for weight[432]= 0.00000000000130829007	 for label 0	 block: 0
first term for weight[432]= -0.0043147141	 for label 0	 block: 2
second term for weight[432]= 0.00000000000130829007	 for label 0	 block: 1
first term for weight[432]= -0.0113837932	 for label 0	 block: 3
second term for weight[432]= 0.00000000000130829007	 for label 0	 block: 2
second term for weight[432]= 0.00000000000064099171	 for label 0	 block: 3
Iteration no: 4, weight[432] = 0.0000349283
Iteration no: 10, weight[432] = 0.0001412027
Training (log)loss: 2.2674695371	 thread:0
6363 correct out of 60000.	 Testing accuracy: 0.106050	 thread:0
1042 correct out of 10000.	 Testing accuracy: 0.104200	 thread:0
Iteration no: 100, weight[432] = 0.0003003274
Training (log)loss: 2.0381258832	 thread:0
8672 correct out of 60000.	 Testing accuracy: 0.144533	 thread:0
1423 correct out of 10000.	 Testing accuracy: 0.142300	 thread:0
Iteration no: 1000, weight[432] = 0.0049065678
Training (log)loss: -0.5372687848	 thread:0
11286 correct out of 60000.	 Testing accuracy: 0.188100	 thread:0
1838 correct out of 10000.	 Testing accuracy: 0.183800	 thread:0
Iteration no: 10000, weight[432] = 0.0412090485
Training (log)loss: -24.3473795688	 thread:0
17089 correct out of 60000.	 Testing accuracy: 0.284817	 thread:0
2818 correct out of 10000.	 Testing accuracy: 0.281800	 thread:0
Iteration no: 100000, weight[432] = 0.2746956575
Training (log)loss: -170.6985874591	 thread:0
21045 correct out of 60000.	 Testing accuracy: 0.350750	 thread:0
3428 correct out of 10000.	 Testing accuracy: 0.342800	 thread:0
first term for weight[432]= -0.0015353337	 for label 0	 block: 0
first term for weight[432]= -0.0001790076	 for label 0	 block: 1
second term for weight[432]= 0.00000001190293332094	 for label 0	 block: 0
first term for weight[432]= -0.0003620915	 for label 0	 block: 2
second term for weight[432]= 0.00000001190293332094	 for label 0	 block: 1
first term for weight[432]= 0.0000000000	 for label 0	 block: 3
second term for weight[432]= 0.00000001190298449834	 for label 0	 block: 2
second term for weight[432]= 0.00000001190299046486	 for label 0	 block: 3
Iteration no: 200000, weight[432] = 0.3570900760
Training (log)loss: -237.3758770489	 thread:0
21397 correct out of 60000.	 Testing accuracy: 0.356617	 thread:0
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= -0.0165706961	 for label 0	 block: 1
second term for weight[432]= 0.00000001305183902298	 for label 0	 block: 0
first term for weight[432]= 0.0155515860	 for label 0	 block: 2
second term for weight[432]= 0.00000001305183902298	 for label 0	 block: 1
first term for weight[432]= -0.0001980185	 for label 0	 block: 3
second term for weight[432]= 0.00000001305183902254	 for label 0	 block: 2
second term for weight[432]= 0.00000001305239137864	 for label 0	 block: 3
Iteration no: 400000, weight[432] = 0.3915563878
Training (log)loss: -283.2488458687	 thread:0
21734 correct out of 60000.	 Testing accuracy: 0.362233	 thread:0
3512 correct out of 10000.	 Testing accuracy: 0.351200	 thread:0
first term for weight[432]= 0.0075892724	 for label 0	 block: 0
first term for weight[432]= -0.0002377895	 for label 0	 block: 1
second term for weight[432]= 0.00000001476636371493	 for label 0	 block: 0
first term for weight[432]= -0.0096790140	 for label 0	 block: 2
second term for weight[432]= 0.00000001476636371493	 for label 0	 block: 1
first term for weight[432]= -0.0077459494	 for label 0	 block: 3
second term for weight[432]= 0.00000001476611073869	 for label 0	 block: 2
second term for weight[432]= 0.00000001476611866451	 for label 0	 block: 3
Iteration no: 600000, weight[432] = 0.4430009849
Training (log)loss: -299.0423073782	 thread:0
21954 correct out of 60000.	 Testing accuracy: 0.365900	 thread:0
3510 correct out of 10000.	 Testing accuracy: 0.351000	 thread:0
first term for weight[432]= 0.0041342376	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000001437362094634	 for label 0	 block: 0
first term for weight[432]= 0.0202673427	 for label 0	 block: 2
second term for weight[432]= 0.00000001437362094634	 for label 0	 block: 1
first term for weight[432]= -0.0005375703	 for label 0	 block: 3
second term for weight[432]= 0.00000001437348313794	 for label 0	 block: 2
second term for weight[432]= 0.00000001437348313746	 for label 0	 block: 3
Iteration no: 800000, weight[432] = 0.4311847643
Training (log)loss: -304.6771151450	 thread:0
21966 correct out of 60000.	 Testing accuracy: 0.366100	 thread:0
3506 correct out of 10000.	 Testing accuracy: 0.350600	 thread:0
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0096473805	 for label 0	 block: 1
second term for weight[432]= 0.00000001473298159720	 for label 0	 block: 0
first term for weight[432]= -0.0052403347	 for label 0	 block: 2
second term for weight[432]= 0.00000001473298159720	 for label 0	 block: 1
first term for weight[432]= -0.0012157871	 for label 0	 block: 3
second term for weight[432]= 0.00000001473298159671	 for label 0	 block: 2
second term for weight[432]= 0.00000001473266001687	 for label 0	 block: 3
Iteration no: 999999, weight[432] = 0.4419862566
Training (log)loss: -307.9696781270	 thread:0
22070 correct out of 60000.	 Testing accuracy: 0.367833	 thread:0
3519 correct out of 10000.	 Testing accuracy: 0.351900	 thread:0

Time elapsed in training = 560.280800 sec
Time elapsed in training per iteration = 0.000560 sec
new loss: -307.969678 

No of iterations for each thread block: 1000000
No of threads in each block: 1024
No of blocks: 4
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3519 correct out of 10000.	 Testing accuracy: 0.351900	 thread:0
End









[ir967@cuda2 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
Accuracy is too high. Check if weights are zeros.
weight[432] = 0.0000000000
Enter iterations (> 10):
1000000
old loss: 2.302585 
weight[432] = 0.000000
first term for weight[432]= -0.0011764706	 for label 0	 block: 0
first term for weight[432]= -0.0011764706	 for label 0	 block: 1
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 0
second term for weight[432]= 0.00000000000000000000	 for label 0	 block: 1
Iteration no: 0, weight[432] = 0.0000023529
Iteration no: 0, weight[432] = 0.0000023529
Training (log)loss: 2.3016546242	 thread:0
6034 correct out of 60000.	 Testing accuracy: 0.100567	 thread:0
1000 correct out of 10000.	 Testing accuracy: 0.100000	 thread:0
first term for weight[432]= -0.0011764124	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000007843137	 for label 0	 block: 0
second term for weight[432]= 0.00000000000007843137	 for label 0	 block: 1
Iteration no: 1, weight[432] = 0.0000035294
first term for weight[432]= -0.0094080710	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000011764512	 for label 0	 block: 0
second term for weight[432]= 0.00000000000011764512	 for label 0	 block: 1
Iteration no: 2, weight[432] = 0.0000129374
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000000000043124749	 for label 0	 block: 0
second term for weight[432]= 0.00000000000043124749	 for label 0	 block: 1
Iteration no: 3, weight[432] = 0.0000129374
first term for weight[432]= -0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0199862011	 for label 0	 block: 1
second term for weight[432]= 0.00000000000043124749	 for label 0	 block: 0
second term for weight[432]= 0.00000000000043124749	 for label 0	 block: 1
Iteration no: 4, weight[432] = -0.0000070488
first term for weight[432]= -0.0014519465	 for label 0	 block: 0
first term for weight[432]= -0.0002848598	 for label 0	 block: 1
second term for weight[432]= 0.00000000837775848895	 for label 0	 block: 0
second term for weight[432]= 0.00000000837775848895	 for label 0	 block: 1
Iteration no: 200000, weight[432] = 0.2513344915
Training (log)loss: -173.5822624660	 thread:0
21027 correct out of 60000.	 Testing accuracy: 0.350450	 thread:0
3442 correct out of 10000.	 Testing accuracy: 0.344200	 thread:0
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= -0.0187127711	 for label 0	 block: 1
second term for weight[432]= 0.00000001097469884235	 for label 0	 block: 0
second term for weight[432]= 0.00000001097469884235	 for label 0	 block: 1
Iteration no: 400000, weight[432] = 0.3292596780
Training (log)loss: -239.5650074128	 thread:0
21435 correct out of 60000.	 Testing accuracy: 0.357250	 thread:0
3521 correct out of 10000.	 Testing accuracy: 0.352100	 thread:0
first term for weight[432]= 0.0083723613	 for label 0	 block: 0
first term for weight[432]= -0.0002480757	 for label 0	 block: 1
second term for weight[432]= 0.00000001311044311719	 for label 0	 block: 0
second term for weight[432]= 0.00000001311044311719	 for label 0	 block: 1
Iteration no: 600000, weight[432] = 0.3933051692
Training (log)loss: -269.7502429131	 thread:0
21595 correct out of 60000.	 Testing accuracy: 0.359917	 thread:0
3503 correct out of 10000.	 Testing accuracy: 0.350300	 thread:0
first term for weight[432]= 0.0046311390	 for label 0	 block: 0
first term for weight[432]= 0.0000000000	 for label 0	 block: 1
second term for weight[432]= 0.00000001374143413759	 for label 0	 block: 0
second term for weight[432]= 0.00000001374143413759	 for label 0	 block: 1
Iteration no: 800000, weight[432] = 0.4122383930
Training (log)loss: -284.4518513657	 thread:0
21691 correct out of 60000.	 Testing accuracy: 0.361517	 thread:0
3505 correct out of 10000.	 Testing accuracy: 0.350500	 thread:0
first term for weight[432]= 0.0000000000	 for label 0	 block: 0
first term for weight[432]= 0.0086686695	 for label 0	 block: 1
second term for weight[432]= 0.00000001391267411947	 for label 0	 block: 0
second term for weight[432]= 0.00000001391267411947	 for label 0	 block: 1
Iteration no: 999999, weight[432] = 0.4173715549
Training (log)loss: -293.2470999402	 thread:0
21847 correct out of 60000.	 Testing accuracy: 0.364117	 thread:0
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0

Time elapsed in training = 480.411388 sec
Time elapsed in training per iteration = 0.000480 sec
new loss: -293.247100 

No of iterations for each thread block: 1000000
No of threads in each block: 1024
Lambda (Regularization Parameter): 0.001000
Eta (Learning Rate): 0.001000
3500 correct out of 10000.	 Testing accuracy: 0.350000	 thread:0
End









[ir967@cuda2 SGD]$ ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
weight[432] = 0.0000000000
Enter iterations (> 10):
1000000
old loss: 2.302585 
weight[432] = 0.000000
first term for weight[432]= -0.0011764706	 for label 0
second term for weight[432]= 0.00000000000000000000	 for label 0
Iteration no: 0, weight[432] = 0.0000011765
Iteration no: 0, weight[432] = 0.0000011765
Training (log)loss: 2.3019360710	 thread:0
6340 correct out of 60000.	 Testing accuracy: 0.105667	 thread:0
1048 correct out of 10000.	 Testing accuracy: 0.104800	 thread:0
first term for weight[432]= -0.0011764046	 for label 0
second term for weight[432]= 0.00000000000003921569	 for label 0
Iteration no: 1, weight[432] = 0.0000023529
first term for weight[432]= -0.0094095867	 for label 0
second term for weight[432]= 0.00000000000007842917	 for label 0
Iteration no: 2, weight[432] = 0.0000117625
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 3, weight[432] = 0.0000117625
first term for weight[432]= -0.0000000000	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 4, weight[432] = 0.0000117625
first term for weight[432]= 0.0035301030	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 5, weight[432] = 0.0000082324
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000027441196	 for label 0
Iteration no: 6, weight[432] = 0.0000082324
first term for weight[432]= -0.0011764156	 for label 0
second term for weight[432]= 0.00000000000027441196	 for label 0
Iteration no: 7, weight[432] = 0.0000094088
first term for weight[432]= -0.0011765513	 for label 0
second term for weight[432]= 0.00000000000031362582	 for label 0
Iteration no: 8, weight[432] = 0.0000105853
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000035284419	 for label 0
Iteration no: 9, weight[432] = 0.0000105853
Iteration no: 200000, weight[432] = 0.1490432103
Training (log)loss: -115.4814183372	 thread:0
20730 correct out of 60000.	 Testing accuracy: 0.345500	 thread:0
3364 correct out of 10000.	 Testing accuracy: 0.336400	 thread:0
Iteration no: 400000, weight[432] = 0.2362742398
Training (log)loss: -183.0276989556	 thread:0
21133 correct out of 60000.	 Testing accuracy: 0.352217	 thread:0
3453 correct out of 10000.	 Testing accuracy: 0.345300	 thread:0
Iteration no: 600000, weight[432] = 0.3012493066
Training (log)loss: -222.9435874182	 thread:0
21368 correct out of 60000.	 Testing accuracy: 0.356133	 thread:0
3473 correct out of 10000.	 Testing accuracy: 0.347300	 thread:0
Iteration no: 800000, weight[432] = 0.3416902986
Training (log)loss: -248.6937980815	 thread:0
21455 correct out of 60000.	 Testing accuracy: 0.357583	 thread:0
3479 correct out of 10000.	 Testing accuracy: 0.347900	 thread:0
Iteration no: 999999, weight[432] = 0.3542084094
Training (log)loss: -265.4477568488	 thread:0
21591 correct out of 60000.	 Testing accuracy: 0.359850	 thread:0
3499 correct out of 10000.	 Testing accuracy: 0.349900	 thread:0
Training ran for 449.028698
new loss: -265.447757 
3499 correct out of 10000.	 Testing accuracy: 0.349900	 thread:0
End







[ir967@cuda2 SGD]$ ./hogwildSGD
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
weight[432] = 0.0000000000
Enter iterations (> 10):
100000
old loss: 2.302585 
weight[432] = 0.000000
first term for weight[432]= -0.0011764706	 for label 0
second term for weight[432]= 0.00000000000000000000	 for label 0
Iteration no: 0, weight[432] = 0.0000011765
Iteration no: 0, weight[432] = 0.0000011765
Training (log)loss: 2.3019360710	 thread:0
6340 correct out of 60000.	 Testing accuracy: 0.105667	 thread:0
1048 correct out of 10000.	 Testing accuracy: 0.104800	 thread:0
first term for weight[432]= -0.0011764046	 for label 0
second term for weight[432]= 0.00000000000003921569	 for label 0
Iteration no: 1, weight[432] = 0.0000023529
first term for weight[432]= -0.0094095867	 for label 0
second term for weight[432]= 0.00000000000007842917	 for label 0
Iteration no: 2, weight[432] = 0.0000117625
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 3, weight[432] = 0.0000117625
first term for weight[432]= -0.0000000000	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 4, weight[432] = 0.0000117625
first term for weight[432]= 0.0035301030	 for label 0
second term for weight[432]= 0.00000000000039208206	 for label 0
Iteration no: 5, weight[432] = 0.0000082324
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000027441196	 for label 0
Iteration no: 6, weight[432] = 0.0000082324
first term for weight[432]= -0.0011764156	 for label 0
second term for weight[432]= 0.00000000000027441196	 for label 0
Iteration no: 7, weight[432] = 0.0000094088
first term for weight[432]= -0.0011765513	 for label 0
second term for weight[432]= 0.00000000000031362582	 for label 0
Iteration no: 8, weight[432] = 0.0000105853
first term for weight[432]= 0.0000000000	 for label 0
second term for weight[432]= 0.00000000000035284419	 for label 0
Iteration no: 9, weight[432] = 0.0000105853
Iteration no: 20000, weight[432] = 0.0163123143
Training (log)loss: -12.6305380636	 thread:0
15885 correct out of 60000.	 Testing accuracy: 0.264750	 thread:0
2626 correct out of 10000.	 Testing accuracy: 0.262600	 thread:0
Iteration no: 40000, weight[432] = 0.0332243599
Training (log)loss: -26.2745915840	 thread:0
17918 correct out of 60000.	 Testing accuracy: 0.298633	 thread:0
2992 correct out of 10000.	 Testing accuracy: 0.299200	 thread:0
Iteration no: 60000, weight[432] = 0.0513505771
Training (log)loss: -39.4850572803	 thread:0
18629 correct out of 60000.	 Testing accuracy: 0.310483	 thread:0
3059 correct out of 10000.	 Testing accuracy: 0.305900	 thread:0
Iteration no: 80000, weight[432] = 0.0694876832
Training (log)loss: -52.6727005281	 thread:0
19685 correct out of 60000.	 Testing accuracy: 0.328083	 thread:0
3236 correct out of 10000.	 Testing accuracy: 0.323600	 thread:0
Iteration no: 99999, weight[432] = 0.0945580015
Training (log)loss: -64.9328740793	 thread:0
20012 correct out of 60000.	 Testing accuracy: 0.333533	 thread:0
3301 correct out of 10000.	 Testing accuracy: 0.330100	 thread:0
Training ran for  67.170169
new loss: -64.932874 
3301 correct out of 10000.	 Testing accuracy: 0.330100	 thread:0
End









[ir967@cuda2 SGD]$ rm -f hogwildSGD; nvcc -arch=compute_30 -o hogwildSGD hogwildSGD.cu -Xcompiler -fopenmp --maxrregcount 60 --expt-relaxed-constexpr; cuda-memcheck --print-limit 4 hogwildSGD
========= CUDA-MEMCHECK
Started main.
trainingData[24356][432] = -0.0117647059
trainingLabel[24356] = 3
Data loaded to Host.
Data loaded to device.
10000 correct out of 10000.	 Testing accuracy: 1.000000	 thread:0
weight[432] = 0.0000000000
Enter iterations (> 10):
10000
old loss: 138155.105580 
weight[432] = 0.000000
first term for weight[432]= 0.0011764706	 for label 0
Iteration no: 0, weight[432] = -0.0000011765
Iteration no: 0, weight[432] = -0.0000011765
Training (log)loss: 138194.0527555375	 thread:0
8952 correct out of 10000.	 Testing accuracy: 0.895200	 thread:0
first term for weight[432]= 0.0011765366	 for label 0
Iteration no: 1, weight[432] = -0.0000023530
first term for weight[432]= 0.0094139413	 for label 0
Iteration no: 2, weight[432] = -0.0000117669
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 3, weight[432] = -0.0000117669
first term for weight[432]= 0.0000000000	 for label 0
Iteration no: 4, weight[432] = -0.0000117669
first term for weight[432]= -0.0035287200	 for label 0
Iteration no: 5, weight[432] = -0.0000082382
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 6, weight[432] = -0.0000082382
first term for weight[432]= 0.0011765250	 for label 0
Iteration no: 7, weight[432] = -0.0000094148
first term for weight[432]= 0.0011763894	 for label 0
Iteration no: 8, weight[432] = -0.0000105911
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 9, weight[432] = -0.0000105911
first term for weight[432]= 0.0502122175	 for label 0
Iteration no: 10, weight[432] = -0.0000608034
first term for weight[432]= 0.0000000000	 for label 0
Iteration no: 11, weight[432] = -0.0000608034
first term for weight[432]= 0.0000000000	 for label 0
Iteration no: 12, weight[432] = -0.0000608034
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 13, weight[432] = -0.0000608034
first term for weight[432]= -0.0113623355	 for label 0
Iteration no: 14, weight[432] = -0.0000494410
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 15, weight[432] = -0.0000494410
first term for weight[432]= -0.0000000000	 for label 0
Iteration no: 16, weight[432] = -0.0000494410
first term for weight[432]= 0.0321135975	 for label 0
Iteration no: 17, weight[432] = -0.0000815546
first term for weight[432]= 0.0242830718	 for label 0
Iteration no: 18, weight[432] = -0.0001058377
first term for weight[432]= 0.0015659628	 for label 0
Iteration no: 19, weight[432] = -0.0001074037
Iteration no: 2000, weight[432] = -0.0006848793
Training (log)loss: 233020.8498889887	 thread:0
832 correct out of 10000.	 Testing accuracy: 0.083200	 thread:0
Iteration no: 4000, weight[432] = -0.0031341027
Training (log)loss: 329837.0899513204	 thread:0
777 correct out of 10000.	 Testing accuracy: 0.077700	 thread:0
Iteration no: 6000, weight[432] = -0.0062459563
Training (log)loss: 422959.9905052827	 thread:0
681 correct out of 10000.	 Testing accuracy: 0.068100	 thread:0
Iteration no: 8000, weight[432] = -0.0074912067
Training (log)loss: 512778.1856922539	 thread:0
751 correct out of 10000.	 Testing accuracy: 0.075100	 thread:0
Iteration no: 9999, weight[432] = -0.0099771247
Training (log)loss: 606541.8567649147	 thread:0
617 correct out of 10000.	 Testing accuracy: 0.061700	 thread:0
Training ran for 2560.989613
new loss: 606541.856765 
617 correct out of 10000.	 Testing accuracy: 0.061700	 thread:0
End





[ir967@cuda2 SGD]$ ./hogwildSGD 
Started main.
Data loaded to Host.
Data loaded to device.
973 correct out of 10000.	 Testing accuracy: 0.097300	 thread:0
weight[103] = 1.603103
Enter iterations (> 10):
1000000
old loss: 354262.369810 
weight[107] = 0.561441
weight[32] = 1.402307
Training (log)loss: 354296.115270	 thread:0
973 correct out of 10000.	 Testing accuracy: 0.097300	 thread:0
weight[32] = 1.402298
Training (log)loss: 16786871.838336	 thread:0
1009 correct out of 10000.	 Testing accuracy: 0.100900	 thread:0
weight[32] = 1.402288
Training (log)loss: 34521393.015290	 thread:0
1009 correct out of 10000.	 Testing accuracy: 0.100900	 thread:0
weight[32] = 1.402279
Training (log)loss: 52214055.577273	 thread:0
1009 correct out of 10000.	 Testing accuracy: 0.100900	 thread:0
weight[32] = -nan
Training (log)loss: -nan	 thread:0
0 correct out of 10000.	 Testing accuracy: 0.000000	 thread:0

weight[32] = -nan
Training (log)loss: -nan	 thread:0
0 correct out of 10000.	 Testing accuracy: 0.000000	 thread:0
Training ran for 418.782644
new loss: -nan 
0 correct out of 10000.	 Testing accuracy: 0.000000	 thread:0
End
